 with torch.no_grad():
        plt.figure()
        plt.plot(train_loss.keys(), train_loss.values(), 'r-')
        plt.plot(val_loss.keys(), val_loss.values(), 'g-')
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.figure()
        plt.plot(f_train.keys(), f_train.values(), 'r-')
        plt.plot(f_test.keys(), f_test.values(), 'g-')
        plt.xlabel('Epochs')
        plt.ylabel('Friction Factor')
        plt.figure()
        ff_distribution = {}
        for key_tensor, value_tensor in f_dist.items():
        # Convert the tensors to numpy arrays
            key_array = np.array(key_tensor.detach())
            value_array = np.array(value_tensor.detach())
            # Unpack the elements from the tensors
            for key_elem, value_elem in zip(key_array, value_array):
            # Add the unpacked elements to the new dictionary
                ff_distribution[key_elem] = value_elem
        plt.scatter(ff_distribution.keys(), ff_distribution.values(), 'f_Real = {fval[f]}')
        plt.ylabel('Friction Factor')
        plt.xlabel('Eta')
        plt.ylim([0,1]) 