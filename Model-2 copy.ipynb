{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import torch\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.train' from '/Users/ramtarun/Desktop/Cambridge/Friction-Factor-Estimation-PINN/src/train.py'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.HyperParameters as hp \n",
    "import src.data as dt \n",
    "import src.model3 as Model \n",
    "import src.train as trainer\n",
    "\n",
    "importlib.reload(hp)\n",
    "importlib.reload(dt)\n",
    "importlib.reload(Model)\n",
    "importlib.reload(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('/Users/ramtarun/Desktop/Cambridge/Indirect-Noise-in-Nozzles/Data/Data_PINN_subsonic_geom_linvelsup_f0-0.1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINN(\n",
       "  (loss_function): MSELoss()\n",
       "  (rnn): PhyGRU(\n",
       "    (activation): ModuleList(\n",
       "      (0): ReLU()\n",
       "      (1): Tanh()\n",
       "      (2): ReLU()\n",
       "      (3): Tanh()\n",
       "      (4): ReLU()\n",
       "      (5): Tanh()\n",
       "      (6): ReLU()\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "    (gru): GRU(2, 6, batch_first=True)\n",
       "    (hidden_layers): ModuleList(\n",
       "      (0): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (1): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (2): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (3): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (4): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (5): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (6): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (7): Linear(in_features=6, out_features=6, bias=True)\n",
       "    )\n",
       "    (output_layer): Linear(in_features=6, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINN_model = Model.PINN(hp.input_size, hp.output_size, hp.hidden_sizes, hp.activations)\n",
    "PINN_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3905, -0.2932],\n",
       "         [ 0.0226, -0.3482],\n",
       "         [ 0.2162, -0.1610],\n",
       "         [-0.3004, -0.2534],\n",
       "         [-0.0871,  0.0238],\n",
       "         [-0.0410,  0.1134],\n",
       "         [ 0.2117,  0.1262],\n",
       "         [ 0.0298, -0.2263],\n",
       "         [-0.3173, -0.1318],\n",
       "         [ 0.0713,  0.1469],\n",
       "         [ 0.2014, -0.0291],\n",
       "         [-0.2010, -0.2898],\n",
       "         [ 0.0398, -0.1266],\n",
       "         [ 0.1324,  0.1057],\n",
       "         [-0.0029,  0.3590],\n",
       "         [-0.2614,  0.2066],\n",
       "         [ 0.2066,  0.2165],\n",
       "         [-0.2667, -0.0097]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.3418,  0.2462, -0.0295,  0.2548,  0.2056,  0.0105],\n",
       "         [-0.3495,  0.0423,  0.0112,  0.1561, -0.0493, -0.3081],\n",
       "         [-0.1671, -0.3878,  0.1052,  0.0428,  0.1008,  0.1081],\n",
       "         [-0.0174, -0.0522, -0.0975, -0.2165,  0.3765,  0.3863],\n",
       "         [ 0.0033, -0.1096,  0.3431,  0.0118, -0.1792, -0.3169],\n",
       "         [-0.3320, -0.4052, -0.3215,  0.4004, -0.3126,  0.1731],\n",
       "         [-0.1176,  0.3092,  0.0403, -0.2693,  0.3312,  0.1958],\n",
       "         [ 0.0457,  0.1555, -0.0367,  0.2623, -0.3322,  0.1065],\n",
       "         [ 0.2896,  0.3292,  0.3803, -0.1761, -0.1286, -0.1247],\n",
       "         [-0.0953,  0.4058, -0.3559, -0.1843, -0.2155, -0.0932],\n",
       "         [ 0.3733,  0.0006, -0.2800, -0.1845, -0.2075, -0.1790],\n",
       "         [ 0.0302,  0.1475,  0.2427,  0.0476, -0.1129, -0.2668],\n",
       "         [-0.2343, -0.0404,  0.1588, -0.2997, -0.3585, -0.1031],\n",
       "         [ 0.0455,  0.0358,  0.2598,  0.0414,  0.2633,  0.3821],\n",
       "         [ 0.2611, -0.3298,  0.0665, -0.3226,  0.2686, -0.2686],\n",
       "         [ 0.1310, -0.3264, -0.4048, -0.2299,  0.3863,  0.3881],\n",
       "         [-0.2922,  0.1293, -0.0946, -0.2685, -0.0093,  0.0216],\n",
       "         [ 0.0290,  0.1603,  0.1203, -0.2886,  0.3142, -0.3702]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1750,  0.2256, -0.0788, -0.1075,  0.1001,  0.0865,  0.0370,  0.2404,\n",
       "          0.0240,  0.1972,  0.0445,  0.2373, -0.0380, -0.3643,  0.2265,  0.0242,\n",
       "          0.0347,  0.3535], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3040, -0.3428, -0.2223, -0.2171,  0.1235, -0.1526, -0.1222, -0.0036,\n",
       "          0.2930, -0.3405,  0.2401, -0.0231, -0.0383,  0.3536, -0.2244, -0.3866,\n",
       "         -0.0025,  0.1077], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.3243,  0.1295,  0.3248,  0.3723,  0.3511, -0.2953],\n",
       "         [-0.3455,  0.2693,  0.0471,  0.0983,  0.3246,  0.3586],\n",
       "         [ 0.0419, -0.1111,  0.1642, -0.2724,  0.3387,  0.2195],\n",
       "         [ 0.3379,  0.2501, -0.2077,  0.0932, -0.0839,  0.2406],\n",
       "         [-0.2195,  0.2113, -0.2391,  0.0538, -0.1606, -0.3286],\n",
       "         [ 0.1654, -0.2664, -0.3968, -0.1662,  0.3875, -0.2137]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2112,  0.3836,  0.2593, -0.0929, -0.2042,  0.2383],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.3629, -0.1104, -0.1824,  0.2101,  0.2945,  0.2497],\n",
       "         [-0.1341, -0.1957, -0.3377, -0.2640,  0.2172, -0.3319],\n",
       "         [-0.0039,  0.3794,  0.0752,  0.3567, -0.2359, -0.2771],\n",
       "         [-0.0458,  0.2300, -0.1085, -0.0637,  0.2554,  0.0964],\n",
       "         [ 0.0330, -0.2589, -0.2949,  0.0623, -0.0117,  0.2365],\n",
       "         [-0.1507,  0.1020, -0.3732,  0.1773, -0.1560, -0.2888]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1651, -0.3641,  0.0905,  0.1090,  0.0593, -0.3361],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2028, -0.1940, -0.1237, -0.3744, -0.1248,  0.0711],\n",
       "         [-0.2542, -0.2099, -0.1808,  0.2312,  0.3804,  0.2841],\n",
       "         [-0.0595, -0.0223, -0.3694, -0.2371,  0.0878,  0.3381],\n",
       "         [ 0.0104, -0.2093,  0.3077,  0.3018, -0.2523, -0.3325],\n",
       "         [ 0.2267,  0.1949,  0.3589,  0.0179,  0.1124,  0.1586],\n",
       "         [ 0.2650, -0.3534,  0.0885,  0.4033,  0.3732,  0.3101]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1629, -0.1351, -0.1189,  0.3023,  0.0517,  0.1200],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0998,  0.0954, -0.3192,  0.2122, -0.2545, -0.3573],\n",
       "         [ 0.3089,  0.2954,  0.2953,  0.4057,  0.1260, -0.0906],\n",
       "         [ 0.1418,  0.0759, -0.1862,  0.1926,  0.2699, -0.2833],\n",
       "         [-0.1092, -0.1054,  0.3930, -0.2135,  0.3008, -0.2524],\n",
       "         [ 0.3911, -0.0910,  0.1297,  0.1300,  0.2996, -0.0573],\n",
       "         [-0.2188, -0.1351,  0.0406, -0.2209, -0.1191, -0.0455]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0201, -0.3445,  0.0514, -0.3294,  0.0670,  0.2659],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1417, -0.0335, -0.1014,  0.2988,  0.1944,  0.3996],\n",
       "         [-0.3352, -0.2537, -0.0875, -0.3934,  0.1067,  0.1028],\n",
       "         [-0.2390,  0.2443,  0.2119, -0.1050, -0.0392,  0.0303],\n",
       "         [ 0.0586,  0.1234,  0.3115, -0.1043, -0.2399,  0.2526],\n",
       "         [-0.3242,  0.3111,  0.1074,  0.2114, -0.1006, -0.1144],\n",
       "         [-0.0310, -0.2198, -0.2974, -0.1768, -0.0068, -0.2399]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0269,  0.4007,  0.1504,  0.2671, -0.0691, -0.1813],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.2786e-01, -3.8516e-01, -2.0659e-01,  1.0753e-01, -2.8381e-01,\n",
       "          -5.9542e-02],\n",
       "         [-3.0414e-01, -2.9957e-01, -4.0557e-01,  2.2890e-03, -3.7182e-02,\n",
       "          -1.3688e-01],\n",
       "         [-1.7613e-05,  3.7781e-01,  2.6596e-01, -3.3608e-03, -6.2793e-03,\n",
       "           2.3490e-01],\n",
       "         [-2.3398e-01, -4.5907e-03,  3.7468e-01,  7.4439e-02,  1.5313e-01,\n",
       "          -2.3625e-01],\n",
       "         [-2.3007e-01, -2.0129e-02, -3.3399e-01, -1.4076e-01,  3.3845e-02,\n",
       "           2.6763e-01],\n",
       "         [-5.0730e-02, -4.0504e-01,  1.1584e-01,  1.0757e-01,  2.9192e-01,\n",
       "           3.3640e-01]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2204, -0.1543,  0.3457, -0.2491,  0.0542, -0.2956],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1284, -0.3582, -0.1888, -0.0841, -0.0373, -0.0642],\n",
       "         [-0.0260,  0.2040, -0.3716,  0.3503,  0.1200,  0.2503],\n",
       "         [ 0.3798,  0.0507, -0.2271, -0.2237, -0.1737, -0.1521],\n",
       "         [-0.3001,  0.0473, -0.3025,  0.3620,  0.0473,  0.0614],\n",
       "         [-0.0574,  0.3159,  0.3416,  0.2916, -0.1876,  0.1690],\n",
       "         [ 0.1281,  0.0525, -0.1303, -0.3476, -0.2899, -0.3916]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3323,  0.2758, -0.1477, -0.1566, -0.2599,  0.1739],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.3450,  0.2969, -0.0206, -0.2960, -0.1279,  0.2435],\n",
       "         [-0.3753,  0.1417, -0.2649,  0.1444, -0.1711,  0.3839],\n",
       "         [-0.0325,  0.1700,  0.1672, -0.2255,  0.1088,  0.0022],\n",
       "         [ 0.0071, -0.3418, -0.0860,  0.0035, -0.2598, -0.0870],\n",
       "         [ 0.3603,  0.1260, -0.2986, -0.2010,  0.2374,  0.1734],\n",
       "         [-0.1021,  0.2112,  0.1298, -0.1576, -0.3156, -0.1523]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1163, -0.2555, -0.3317,  0.0967, -0.1627, -0.0150],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.1170e-04,  7.9251e-02,  2.3644e-01,  3.2328e-01,  1.5270e-01,\n",
       "           2.1068e-01],\n",
       "         [ 9.2134e-02, -2.1171e-01, -1.3567e-01,  2.8372e-01, -7.8698e-02,\n",
       "           8.0293e-02],\n",
       "         [-1.2267e-01,  1.3245e-01,  2.5905e-01,  2.1824e-01,  2.2038e-01,\n",
       "           9.2770e-02],\n",
       "         [ 1.5580e-01, -1.7786e-02,  1.5381e-02, -2.8990e-01, -3.1960e-01,\n",
       "          -4.0708e-01]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3784, -0.3610, -0.0703,  0.2522], requires_grad=True)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(PINN_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(PINN_model.parameters())\n",
    "# optimizer = torch.optim.Adam([{'params' : params[1::]},{'params' : params[-1], 'lr': hp.ff_learning_rate}], lr = hp.learning_rate, amsgrad = True)   \n",
    "optimizer = torch.optim.Adam(params=params, lr = hp.learning_rate, amsgrad = True)   \n",
    "# optimizer = torch.optim.LBFGS(params, hp.ff_learning_rate, \n",
    "#                               max_iter = hp.epochs, \n",
    "#                               max_eval = None, \n",
    "#                               tolerance_grad = 1e-11, \n",
    "#                               tolerance_change = 1e-11, \n",
    "#                               history_size = 100, \n",
    "#                               line_search_fn = 'strong_wolfe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PINN' object has no attribute 'dnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m train_loader, val_loader \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mDataTransformer(inputs, targets, meanflow, TrainingSet\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# ### Model 3\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# batch_size = 32\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# sequence_length = len(inputs) // batch_size\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m#     input_data = batch.view(batch_size, sequence_length, 1)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#     train_loader.append(input_data)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m train_loss, val_loss, f_train, f_test, f_dist \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(train_loader, val_loader, hp\u001b[39m.\u001b[39;49mepochs, optimizer, PINN_model, N)\n\u001b[1;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     18\u001b[0m     plt\u001b[39m.\u001b[39mfigure() \n",
      "File \u001b[0;32m~/Desktop/Cambridge/Friction-Factor-Estimation-PINN/src/train.py:42\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, epochs, optimizer, PINN_model, N)\u001b[0m\n\u001b[1;32m     40\u001b[0m val_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m k, (A, B, C) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(val_loader):\n\u001b[0;32m---> 42\u001b[0m     u_pred \u001b[39m=\u001b[39m PINN_model\u001b[39m.\u001b[39;49mdnn(A)[:, :\u001b[39m3\u001b[39m]\n\u001b[1;32m     43\u001b[0m     val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm((B\u001b[39m-\u001b[39mu_pred),\u001b[39m2\u001b[39m)\u001b[39m/\u001b[39mtorch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(B,\u001b[39m2\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39m#   val_loss += PINN_model.Loss(A, B, C).item()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PINN' object has no attribute 'dnn'"
     ]
    }
   ],
   "source": [
    "fval = [0.1  , 0.06 , 0.04, 0.01]\n",
    "\n",
    "# for f in fval:\n",
    "inputs, targets, meanflow =  dt.DataPreprocessing(data, ff=0.01)\n",
    "N = inputs.shape[1]\n",
    "train_loader, val_loader = dt.DataTransformer(inputs, targets, meanflow, TrainingSet=True)\n",
    "# ### Model 3\n",
    "# batch_size = 32\n",
    "# sequence_length = len(inputs) // batch_size\n",
    "# # Reshape the input tensors within the DataLoader\n",
    "# train_loader = []\n",
    "# for batch in Train_loader:\n",
    "#     input_data = batch.view(batch_size, sequence_length, 1)\n",
    "#     train_loader.append(input_data)\n",
    "\n",
    "train_loss, val_loss, f_train, f_test, f_dist = trainer.train(train_loader, val_loader, hp.epochs, optimizer, PINN_model, N)\n",
    "with torch.no_grad():\n",
    "    plt.figure() \n",
    "    plt.plot(train_loss.keys(), train_loss.values(), 'r-', label='Training Loss')\n",
    "    plt.plot(val_loss.keys(), val_loss.values(), 'g-', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.plot(f_train.keys(), f_train.values(), 'r-', label='Training Friction Factor')\n",
    "    plt.plot(f_test.keys(), f_test.values(), 'g-', label='Validation Friction Factor')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Friction Factor')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    ff_distribution = {}\n",
    "    for key_tensor, value_tensor in f_dist.items():\n",
    "    # Convert the tensors to numpy arrays\n",
    "        key_array = np.array(key_tensor.detach())\n",
    "        value_array = np.array(value_tensor.detach())\n",
    "        # Unpack the elements from the tensors\n",
    "        for key_elem, value_elem in zip(key_array, value_array):\n",
    "        # Add the unpacked elements to the new dictionary\n",
    "            ff_distribution[key_elem] = value_elem\n",
    "        \n",
    "        \n",
    "ff_distribution = dict(sorted(ff_distribution.items()))\n",
    "plt.plot(ff_distribution.keys(), ff_distribution.values(), label='Friction Factor Variation along the Nozzle')\n",
    "plt.ylabel('Friction Factor')\n",
    "plt.xlabel('Eta')\n",
    "plt.ylim([0,1]) \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(inputs[:,1], targets)\n",
    "plt.plot(inputs[:,1],PINN_model.dnn(inputs).detach(), 'k-.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
